                                 QUICK START
                              ~~~~~~~~~~~~~~~~~
A. Requirements
B. GBS pipeline
    Start here if you received one or more compressed FASTQ files, from a GBS 
    experiment, and want to start using NGSEP.
C. WGS pipeline
    Start here if you have a directory full of FASTQ files, each for a Whole 
    Genome Sequencing experiment of a different sample.
D. Production pipeline
    We offer bash scripts for parallelizing processes when working with a big 
    amount of samples.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                          ~~~~~ Requirements ~~~~~

- For basic usage:
    - Java 1.8
    - Reference genome: in FASTA format
    - Sample files, this can be:
        - FASTQ files: one for single-end reads or two for paired-end reads;
                    a single one for all your samples or one for each sample; 
                    compressed or not.
        - BAM files: if mapping was already done, the BAM/SAM files for each 
                    sample.
- For sorting and file management:
    - File picard.jar. Download from http://github.com/broadinstitute/picard/releases/latest)
    - Samtools. Follow instructions at http://samtools.sourceforge.net/
- For annotation:
    - GFF3 file: corresponding to the reference genome 
    (as specified in www.sequenceontology.org/gff3.shtml)


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                          ~~~~~ GBS pipeline ~~~~~
_________________
0. Demultiplexing:
    {INPUT: single or paired end FASTQ files directly from the sequencer - 
                     - OUTPUT: one or two FASTQ files for each of your samples}

    - If you haven't done this already, you probably have a huge FASTQ file 
    with all your samples mixed in it, so the first step would be to classify 
    them according to their Barcodes, Lane, and Flowcell. If you already have 
    one FASTQ file per sample, skip this step.

        $ java -jar NGSEPcore_<VERSION>.jar Demultiplex -t <TRIM_SEQ> -o <DIR> -d <LANE_DESCRIPTOR> -i <INDEX_FILE> >& demultiplexing.log

    <FASTQ_FILE> : That huge FASTQ file as it came out from the sequencer.
    <TRIM_SEQ>   : Adapter sequence for trimming at the end of the reads; IUPAC
    <DIR>        : Directory where you want to keep your FASTQ files.
    <INDEX_FILE> : The file containing the classification of each sample, 
                   it should look like this:
                  _________________________________________________ 
                  |Flowcell      Lane      Barcode    sampleID    ...
                  |CXXKGTWETC    7         ACTCA      SMPL_A      ...
                  |CXXKGTWETC    7         ACTCG      SMPL_B      ...
                  |...           ...       ...        ...         ...

    <LANE_DESCRIPTOR> : Tab-delimited File with the location of the files to be
                        demultiplexed. Columns are: Flowcell, lane, fastq file
                        (which can be gzip compressed) and a second fastq for 
                        paired-end reads. looking like this:
       _________________________________________________ 
       |CXXKGTWETC    7       /gbs/CXXKGTWETC.fq.gz   
       |CXKTRDLFJF    3       /gbs/CXKTRDLFJF_1.fq.gz   /gbs/CXKTRDLFJF_2.fq.gz
       |...           ...     ...                       ...
       
___________
1. Mapping:
    {INPUT: one or two FASTQ files for each of your samples - 
                               - OUTPUT: one BAM file for each of your samples}

    - (Optional) For large genomes, first, build an index of the reference genome. Has to be done only once:

        $ java -jar NGSEPcore_<VERSION>.jar GenomeIndexer -i <REF.fa> -o <REF_ix>

    - Map each of the FASTQ files to the reference genome

        * For Paired-End, Illumina reads:

        $ java -jar NGSEPcore_<VERSION>.jar ReadsAligner -r <REF.fa> -i <SMPL>_1.fastq -i2 <SMPL>_2.fastq -o <SMPL>.bam > <SMPL>_aln.log
        
        * For Single-End, Illumina reads:

        $ java -jar NGSEPcore_<VERSION>.jar ReadsAligner -r <REF.fa> -i <SMPL>.fastq -o <SMPL>.bam > <SMPL>_aln.log

	  for large genomes, it will be more efficient in runtime and RAM if you use the option -d to load the <REF_ix> index file generated by GenomeIndexer
	  instead of loading the genome with the -r option
	   
    - Sort the reads by position in the reference genome:   
         
        $ java -jar picard.jar SortSam SO=coordinate CREATE_INDEX=true I=<SMPL>.bam O=<SMPL>_sorted.bam >& <SMPL>_sort.log

    - Check the quality and fragment size of the alignment:

        $ java -jar NGSEPcore_<VERSION>.jar BasePairQualStats -r <REF.fa> -o <SMPL>_readpos.stats *_sorted.bam 
        
    (only for paired end:)
    
        $ java -jar picard.jar CollectInsertSizeMetrics I=<SMPL>_sorted.bam O=<SMPL>_insertLength.stats H=<SMPL>_insertLength.pdf

    <REF.fa> : The FASTA file of the reference genome.
    <REF_ix> : File with the FM-index of the genome
    <SMPL>   : The ID of the sample.
____________________________________
2. Variants Detection and Genotyping:
    {INPUT: one BAM file for each of your samples -
         - OUTPUT: a single VCF file with all the variation in your population}

    - Since version 3.2.0, the command to run the pileup process to identify and genotype variants on a population is the MultsampleVariantsDetector. This command can be executed as follows 

        $ java -jar NGSEPcore_<VERSION>.jar MultisampleVariantsDetector -maxBaseQS 30 -maxAlnsPerStartPos 100 -r <REF.fa> -o population.vcf <BAM_FILES>* >& population.log

    <REF.fa>     : The FASTA file of the reference genome.
    <BAM_FILES>* : List of all the BAM files generated in the previous step
______________
3. Annotation:
    {INPUT: a single VCF file with all the variation in your population -
              - OUTPUT: the annotated VCF file with useful statistics about it}

    - Annotate the variants present in the population VCF file:

        $ java -jar NGSEPcore_<VERSION>.jar VCFAnnotate -i population.vcf -t <GFF3_FILE> -r <REF.fa> -o population_annotated.vcf

    - Calculate the Summary Statistics for your annotated VCF file:

        $ java -jar NGSEPcore_<VERSION>.jar VCFSummaryStats -m 1 -i population_annotated.vcf -o population_summary.stats

    - Compare differences between your samples and find possible duplicates:

        $ java -jar NGSEPcore_<VERSION>.jar CompareVCF -g 0 -d 100 -r <REF.fa> -i population.vcf -o population_sampleComparison.txt

    <REF.fa>    : The FASTA file of the reference genome.
    <GFF3_FILE> : The GFF3 file with annotation for the reference genome.
__________
4. Filter:
    {INPUT: an annotated VCF file with all the variation in your population -
              - OUTPUT: a filtered and annotated VCF file from your population}

    - Apply filters as you wish, the following are only some suggestions:

        $ java -jar NGSEPcore_<VERSION>.jar VCFFilter -d 20 -q 20 -s -fi -m <85%_of_samples> -minMAF 0.05 -saf duplicates_to_remove.txt -fs -i population_annotated.vcf -o population_annotated_filtered.vcf

    - Check the effects of the filters in the VCF:

        $ java -jar NGSEPcore_<VERSION>.jar VCFSummaryStats -m 1 -i population_annotated_filtered.vcf -o population_filtered_summary.stats
______________
5. Imputation:
    {INPUT: a filtered VCF file from your population -
                          - OUTPUT: a full VCF file, without any missing value}

    - If you are willing to reduce the number of missing data points in a VCF, 
    NGSEP offers a module for haplotype imputation:

        $ java -jar NGSEPcore_<VERSION>.jar VCFImpute -i population_annotated_filtered.vcf -o population_annotated_filtered >& population_imputation.log
__________
6. Export:
    {INPUT: a filtered and annotated VCF file from your population -
         - OUTPUT: the information from your population in any format you want}

    - That's it! at this point you have the full VCF for your study population,
    it has:
        - high quality SNPs
        - no duplicate samples
        - functional annotation
        - no missing data points
    - For further analysis, export your VCF file into one of the most common 
    formats for NGS analysis:

        $ java -jar NGSEPcore_<VERSION>.jar VCFConverter -<FORMAT> -i population_annotated_filtered_imputed.vcf -o population

    <FORMAT> : Any of the following formats: structure, fasta, rrBLUP, matrix, 
               hapmap, spagedi, plink, haploview, emma, powerMarker, eigensoft,
               flapjack, darwin, treeMix, joinMap, phase, fineStructure.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                          ~~~~~ WGS pipeline ~~~~~
___________
1. Mapping:
    {INPUT: one or two FASTQ files for each of your samples -
                               - OUTPUT: one BAM file for each of your samples}


    - Map each of the FASTQ files to the reference genome

        * For Paired-End, Illumina reads:

        $ java -jar NGSEPcore_<VERSION>.jar ReadsAligner -r <REF.fa> -i <SMPL>_1.fastq -i2 <SMPL>_2.fastq -o <SMPL>.bam > <SMPL>_aln.log

        * For Single-End, Illumina reads:

        $ java -jar NGSEPcore_<VERSION>.jar ReadsAligner -r <REF.fa> -i <SMPL>.fastq -o <SMPL>.bam > <SMPL>_aln.log

    - Sort the reads by position in the reference genome:        
    
        $ java -jar picard.jar SortSam SO=coordinate CREATE_INDEX=true I=<SMPL>.bam O=<SMPL>_sorted.bam >& <SMPL>_sort.log
    
    - Check the quality and fragment size of the alignment:

        $ java -jar NGSEPcore_<VERSION>.jar BasePairQualStats -r <REF.fa> -o <SMPL>_readpos.stats <SMPL>_sorted.bam >& <SMPL>_readpos.log
        $ java -jar NGSEPcore_<VERSION>.jar CoverageStats -i <SMPL>_sorted.bam -o <SMPL>_coverage.stats >& <SMPL>_coverage.log
        $ java -jar picard.jar CollectInsertSizeMetrics I=<SMPL>_sorted.bam O=<SMPL>_insertLength.stats H=<SMPL>_insertLength.pdf

    <REF.fa> : The FASTA file of the reference genome.
    <SMPL>   : The ID of the sample.
_______________________________________________________________
2. Variants Detecion and Genotyping (sample-by-sample analysis)
    {INPUT: one BAM file for each of your samples -
         - OUTPUT: a single VCF file with all the variation in your population}

    - First, find all high-quality variants in the population, running the 
    following command for each sample:

        $ java -jar NGSEPcore_<VERSION>.jar SingleSampleVariantsDetector -runRep -runRD -runRP -ignore5 <TRIM_5'> -ignore3 <TRIM_3'> -maxBaseQS 30 -minQuality 40 -maxAlnsPerStartPos 2 -sampleId <SMPL> -r <REF.fa> -i <SMPL>_sorted.bam -o <SMPL>_NGSEP >& <SMPL>_NGSEP.log

        * if you are not sure of how many bases to ignore at each end of the 
          read, run this command on each of your readpos.stats files:

        $ awk '{if($5>0){a[$1]=$3;l=$1}if($1=="Alignments"){print "Read length:",l;print "Positions to ignore:";for(i=1;i<=l;i++){y=a[i]/$3;if(y>0.02)printf(" %d",i);}print "";}}' <SMPL>_readpos.stats

    - Second, collect the position of all the high-quality variants in the 
    population:

        $ java -jar NGSEPcore_<VERSION>.jar MergeVariants -s <SEQ_NAMES> -o variants_list.vcf <VCF_FILES>* >& variants_list.log

    - Third, genotype all your samples in the high-quality positions:

        $ java -jar NGSEPcore_<VERSION>.jar SingleSampleVariantsDetector -knownVariants population_variants.vcf -knownSVs <SMPL>_NGSEP_SV.gff -ignore5 <TRIM_5'> -ignore3 <TRIM_3'> -maxBaseQS 30 -maxAlnsPerStartPos 2 -sampleId <SMPL> -r <REF.fa> -i <SMPL>_sorted.bam -o <SMPL>_NGSEP >& <SMPL>_NGSEP.log

    - Fourth, merge all the genotyped samples in a single VCF file:

        $ java -jar NGSEPcore_<VERSION>.jar VCFMerge -s <SEQ_NAMES> -o population.vcf <VCF_FILES>*

    <REF.fa>     : The FASTA file of the reference genome.
    <SMPL>       : The ID of the sample.
    <TRIM_5'>    : Number of low quality nucleotides to trim from the 5' end.
    <TRIM_3'>    : Number of low quality nucleotides to trim from the 3' end.
    <VCF_FILES>* : List of all the VCF files from the FindVariants step.
    <SEQ_NAMES>  : File with the name of all the sequences present in the 
                   reference genome, generate it by running one of the following commands:
                        $ awk '{if(substr($1,1,1)==">") print substr($1,2) }' <REF.fa> > <SEQ_NAMES>
                        $ samtools faidx <REF.fa>
                   It should look like this:
                   ____________
                   |Chr1
                   |Chr2
                   |Chr3
                   |...
______________
3. Annotation:
    {INPUT: a single VCF file with all the variation in your population -
              - OUTPUT: the annotated VCF file with useful statistics about it}

    - Annotate the variants present in the population VCF file:

        $ java -jar NGSEPcore_<VERSION>.jar VCFAnnotate -i population.vcf -t <GFF3_FILE> -r <REF.fa> -o population_annotated.vcf

    - Calculate the Summary Statistics for your annotated VCF file:

        $ java -jar NGSEPcore_<VERSION>.jar VCFSummaryStats -m 1 -i population_annotated.vcf -o population_summary.stats

    - Compare differences between your samples and find possible duplicates:

        $ java -jar NGSEPcore_<VERSION>.jar VCFComparator -g 0 -d 100 -r <REF.fa> -i population.vcf -o population_sampleComparation.txt

    <REF.fa>    : The FASTA file of the reference genome.
    <GFF3_FILE> : The GFF3 file with annotation for the reference genome.
__________
4. Filter:
    {INPUT: an annotated VCF file with all the variation in your population -
              - OUTPUT: a filtered and annotated VCF file from your population}

    - Apply filters as you wish, the following are only some suggestions:

        $ java -jar NGSEPcore_<VERSION>.jar VCFFilter -d 20 -q 40 -s -fi -m <85%_of_samples> -minMAF 0.05 -saf duplicates_to_remove.txt -fs -i population_annotated.vcf -o population_annotated_filtered.vcf

    - Check the effects of the filters in the VCF:

        $ java -jar NGSEPcore_<VERSION>.jar VCFSummaryStats -m <85%_of_samples> -i population_annotated_filtered.vcf -o population_filtered_summary.stats
__________
5. Export:
    {INPUT: a filtered and annotated VCF file from your population -
         - OUTPUT: the information from your population in any format you want}

    - That's it! at this point you have the full VCF for your study population,
    it has:
        - high quality SNPs
        - no duplicate samples
        - functional annotation
        - few missing data points
    - For further analysis, export your VCF file into one of the most common 
    formats for NGS analysis:

        $ java -jar NGSEPcore_<VERSION>.jar VCFConverter -<FORMAT> -i population_annotated_filtered_imputed.vcf -o population

    <FORMAT> : Any of the following formats: structure, fasta, rrBLUP, matrix, 
               hapmap, spagedi, plink, haploview, emma, powerMarker, eigensoft,
               flapjack, darwin, treeMix, joinMap, phase.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                        ~~~~~ Production pipeline for high coverage WGS ~~~~~

To perform each of the above mentioned tasks in a large number of samples, 
a list of scripts are available at:

        https://sourceforge.net/projects/ngsep/files/training/

The available scripts are:
  for mapping:                                       	runMapping
  for individual variants discovery:                    runNGSEP
  for individual samples genotyping:                    runGenotyping
  for obtaining low quality positions from statistics:  calculateReadposStatsPeaks

These scripts facilitate running the NGSEP pipeline for WGS data in a bash environment. 

> Before running these scripts, the following set up steps must be performed: <
_____
1. Create a directory called "reads" and locate your fastq files in this 
directory. The scripts assume that reads are paired-end, fastq files are 
compressed (with gzip), and for each sample the file names have the following 
format:
<SAMPLE_NAME>_1.fastq.gz
<SAMPLE_NAME>_2.fastq.gz
_____
2. Create a subdirectory at the same level of the "reads" directory 
(usually called "mapping"), and place the scripts in this directory.

_____
3. Save the reference in a single fasta file and index it
using the following command:

  $ java -jar NGSEPcore_<VERSION>.jar GenomeIndexer -i reference.fa -o reference.fmIndex

This can be done at any directory in the file system but this directory needs 
to be set changing the variable "REFERENCE" in each script. Also, create a 
separate text file with the chromosome (scaffold) names, like this:

  $ awk '{if(substr($1,1,1)==">") print substr($1,2) }' reference.fa > reference_seqNames.txt

This file will be used during the merging steps.
_____
4. Download the jar file NGSEPcore_<VERSION>.jar from the NGSEP site:
http://sourceforge.net/projects/ngsep/files/Library/ 
and picard.jar from the Picard site, you will need java 1.8 to run picard:
https://github.com/broadinstitute/picard/releases/latest 
and place them in a convenient directory. Again this can be any directory but it needs 
to be indicated to the scripts changing the variables "PICARD" and "NGSEP". 
The scripts "runMapping", "runNGSEP" and "runGenotyping" do not have a version 
number for the file NGSEPcore.jar; either create a symbolic link without the 
version number:

  $ ln -s NGSEPcore_<VERSION>.jar NGSEPcore.jar

or set the right version in the variable "NGSEP" of each script.
_____
6. Grant execution parameters to every script using the following command;

  $ chmod 755 run* calculateReadposStatsPeaks

Finally, the scripts assume that you are working in a 64 bit environment and 
that java is downloaded and run in 64-bit mode.

        _____________________________________________________________
  #     These are the steps we usually follow to process FASTQ files:      #
_____
1. Align reads to the reference and sort alignments. 

  $ ./runMapping <SAMPLE_NAME>

Besides the bam files with the aligned reads and with the sorted aligned reads,
this script creates the following files: 
  <SAMPLE_NAME>_readpos.stats  
  <SAMPLE_NAME>_coverage.stats 
with quality statistics (differences against the reference genome) and with 
the coverage distribution. The quality statistics can be inspected manually to 
determine how many bases should be ignored in the 5' end and/or in the 3' end 
respectively to call variants. This information can also be calculated using 
the script "calculateReadposStatsPeaks". 
This script calculates the average percentage of differences in the first 75 bp
and then reports read positions (from 5' to 3') in which the percentage of 
differences with the reference is more than 2% and more than two times the 
average. The usage is as follows:

  $ ./calculateReadposStatsPeaks <SAMPLE_NAME>_readpos.stats
_____
2. Call variants against the reference using NGSEP. 
The script runNGSEP has three parameters: sample name, number of bases to 
ignore in the 5' end and number of bases to ignore in the 3' end. 
For example, if the previous step suggests that we should ignore 2bp in the 5' 
end and 4bp in the 3' end, the command would be:

  $ ./runNGSEP <SAMPLE_NAME> 2 4

If all base calls should be taken into account, just include two zeros:

  $ ./runNGSEP <SAMPLE_NAME> 0 0
_____
3. Merge variants from different samples. 
This step is used to determine the sites in which at least one sample has 
a genotype different than the reference. More stringent filters can be done 
at later stages. The command for this is MergeVariants, should look like this:

  $ java -jar /path/to/NGSEPcore_<VERSION>.jar MergeVariants -s /path/to/reference/reference_seqNames.txt -o AllSamples_variants.vcf *_NGSEP.vcf

The file "AllSamples_variants.vcf" is the output file containing all genomic 
locations with some evidence of variation, as explained above. This file still 
does not contain any genotype call for any sample. 
The file can have any name but this name should be updated in the script 
"runGenotyping" (variable KNOWN_VARS) in order to run the next step.
_____
4. Genotype samples on the sites identified in the previous step. 
This is done with the script "runGenotyping", which has the same usage of 
"runNGSEP":

  $ ./runGenotyping <SAMPLE_NAME> 2 4

This should be executed sample by sample. At the end, the files *_NGSEP_gt.vcf 
will contain genotype calls for all sites identified in the step 4 (including 
reference calls).
Usually we do not include quality filters at this stage to retain as much 
information as possible. The quality filter can be done with the VCFFilter 
command of NGSEP.
_____
5. Final merge of the genotype files. 
This is done with the VCFMerge command of NGSEP as follows:

  $ java -jar /path/to/NGSEPcore_<VERSION>.jar VCFMerge -s /path/to/reference/reference_seqNames.txt -o AllSamples_genotypes.vcf *_NGSEP_gt.vcf

The file "AllSamples_genotypes.vcf" will be the final file with genotype calls 
for every site identified in the step 4 and for every sample analyzed. 
This file can be annotated, filtered and converted to other formats using NGSEP
as explained in the README
